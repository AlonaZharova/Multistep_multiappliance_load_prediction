{"cells":[{"cell_type":"markdown","metadata":{"id":"JW8q2Hxl3thA"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/bads/blob/master/tutorials/9_nb_feature_engineering.ipynb) "]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2567,"status":"ok","timestamp":1650668108290,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"},"user_tz":-120},"id":"u5McaQPrIFbW","outputId":"b5d20727-9d3f-42c7-99ba-6d6d59f59938"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"hIm48shZ7hoN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650668111160,"user_tz":-120,"elapsed":2875,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}},"outputId":"467434ad-a62e-43c6-d122-3047f78feab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ax-platform in /usr/local/lib/python3.7/dist-packages (0.2.4)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from ax-platform) (2.7.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from ax-platform) (2.11.3)\n","Requirement already satisfied: botorch==0.6.2 in /usr/local/lib/python3.7/dist-packages (from ax-platform) (0.6.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from ax-platform) (5.5.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from ax-platform) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ax-platform) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ax-platform) (1.3.5)\n","Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from botorch==0.6.2->ax-platform) (1.10.0+cu111)\n","Requirement already satisfied: gpytorch>=1.6 in /usr/local/lib/python3.7/dist-packages (from botorch==0.6.2->ax-platform) (1.6.0)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.7/dist-packages (from botorch==0.6.2->ax-platform) (0.6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9->botorch==0.6.2->ax-platform) (4.1.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->ax-platform) (2.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from multipledispatch->botorch==0.6.2->ax-platform) (1.15.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ax-platform) (2.8.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->ax-platform) (8.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ax-platform) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->ax-platform) (1.1.0)\n"]}],"source":["!pip install ax-platform"]},{"cell_type":"markdown","metadata":{"id":"dC0hxs_4FIQr"},"source":["### Load Data and Set Parameters"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"Wz7fwPe8mgNU","executionInfo":{"status":"ok","timestamp":1650668111161,"user_tz":-120,"elapsed":10,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["# Import standard Python libraries\n","import numpy as np\n","import pandas as pd\n","import time\n","import json\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n","from sklearn.metrics import mean_squared_error\n","import warnings\n","from pickle import load\n","warnings.filterwarnings(\"ignore\")\n","\n","%matplotlib inline  \n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","from numpy import array\n","from ax.service.ax_client import AxClient\n","from ax.utils.notebook.plotting import render, init_notebook_plotting\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Input, LSTM, Concatenate\n","from tensorflow.keras.layers import Dropout, Bidirectional, Flatten\n","from tensorflow.keras.layers import Conv1D, Conv2D\n","from tensorflow.keras.layers import MaxPooling1D, Embedding\n","from tensorflow.keras.layers import RepeatVector, Reshape\n","from tensorflow.keras.layers import TimeDistributed\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import BatchNormalization\n","#from sklearn.neural_network import MLPRegressor\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import plot_model\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.inspection import permutation_importance"]},{"cell_type":"markdown","metadata":{"id":"vp-ZbYIx7IGr"},"source":["#### Helper Functions"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"i42dlocX7IGs","executionInfo":{"status":"ok","timestamp":1650668111161,"user_tz":-120,"elapsed":9,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["def get_accuracy(y_real, y_pred):\n","  deviation_pred = np.abs((y_real - y_pred))\n","  dev_in_percent = (deviation_pred/100)*np.abs(y_real)\n","  dev_in_percent = np.where(dev_in_percent==0, 5, dev_in_percent)\n","  acc_5_lst = np.where(dev_in_percent>5, 0, 1)\n","  acc_5 = acc_5_lst.sum()/len(y_real)\n","  return acc_5\n","\n","def get_accuracy_90(y_real, y_pred):\n","  deviation_pred = np.abs((y_real - y_pred))\n","  dev_in_percent = (deviation_pred/100)*np.abs(y_real)\n","  dev_in_percent = np.where(dev_in_percent==0, 5, dev_in_percent)\n","  acc_5_lst = np.where(dev_in_percent>5, 0, 1)\n","  acc_10 = acc_5_lst.sum()/len(y_real)\n","  return acc_10\n","\n","def get_wmape(y_real, y_pred):\n","  y_real, y_pred = np.array(y_real), np.array(y_pred) \n","  return np.sum(np.abs((y_real - y_pred))) / np.sum(np.abs(y_real))\n","\n","\n","def get_mase_onestep(y_real, y_pred, y_train):\n","    \"\"\"\n","    Computes the MEAN-ABSOLUTE SCALED ERROR forcast error for univariate time series prediction.\n","    \n","    See \"Another look at measures of forecast accuracy\", Rob J Hyndman\n","    \n","    parameters:\n","        training_series: the series used to train the model, 1d numpy array\n","        testing_series: the test series to predict, 1d numpy array or float\n","        prediction_series: the prediction of testing_series, 1d numpy array (same size as testing_series) or float\n","        absolute: \"squares\" to use sum of squares and root the result, \"absolute\" to use absolute values.\n","    \n","    \"\"\"\n","    n = y_train.shape[0]\n","    d = np.abs(np.diff(y_train)).sum()/(n-1)\n","    \n","    errors = np.abs(y_real - y_pred )\n","    return errors.mean()/d\n","\n","def get_mase(actual: np.ndarray, predicted: np.ndarray, naive: np.ndarray):\n","    \"\"\"\n","    Mean Absolute Scaled Error\n","    Baseline (benchmark) is computed with naive forecasting 24 h\n","    \"\"\"\n","    return mean_absolute_error(actual, predicted) / mean_absolute_error(actual, naive)\n"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"g2f65Xct7IGv","executionInfo":{"status":"ok","timestamp":1650668111161,"user_tz":-120,"elapsed":8,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["# Formulas to get all evaluation metrics for flattened and unflattened predictions\n","def evaluate_predictions_flat(actual, predicted, test_y=None, testing=True):\n","\n","    if (actual.shape[1] != 1) or (predicted.shape[1] != 1):\n","      raise AssertionError('Second dimension of actual and predicted array must be 1')\n","\n","    rmse_flat = mean_squared_error(actual, predicted, squared=False)\n","    nrmse_flat = np.asscalar(mean_squared_error(actual, predicted, squared=False)/(max(actual)-min(actual)))\n","    mae_flat = mean_absolute_error(actual, predicted)\n","    wmape_flat = get_wmape(actual, predicted)\n","    mase_flat = get_mase(actual, predicted, test_y)\n","    acc_flat = get_accuracy(actual, predicted)\n","    acc_90_flat = get_accuracy_90(actual, predicted)\n","\n","    print('RMSE/MAE/wMAPE/MASE/NRMSE/ACCURACY')\n","    print(f'{rmse_flat:.2f},{mae_flat:.2f},{wmape_flat:.2f},{mase_flat:.2f}, {nrmse_flat:.2f}, {acc_flat:.2f}')\n","\n","    if not round(wmape_flat,0)==0 and testing==True:\n","      raise AssertionError()\n","\n","    return [rmse_flat, mae_flat, wmape_flat, mase_flat, nrmse_flat, acc_flat, acc_90_flat]\n","\n","def evaluate_predictions_windows(actual, predicted, test_y=None, testing=True):\n","\n","    wmapes_24 = []\n","    rmse_24 = []\n","    nrmse_24 = []\n","    mae_24 = []\n","    mase_24 = []\n","    acc_24 = []\n","    acc_90_24 = []\n","\n","    for i in range(actual.shape[0]):\n","      rmses = mean_squared_error(actual[i], predicted[i], squared=False)\n","      nrmses = mean_squared_error(actual[i], predicted[i], squared=False)/(max(actual[i])-min(actual[i]))\n","      maes = mean_absolute_error(actual[i], predicted[i])\n","      wmapes = get_wmape(actual[i], predicted[i])\n","      mases = get_mase(actual[i], predicted[i], test_y[i])\n","      accs = get_accuracy(actual[i], predicted[i])\n","      accs_90 = get_accuracy_90(actual[i], predicted[i])\n","\n","      rmse_24.append(rmses)\n","      nrmse_24.append(nrmses)\n","      mae_24.append(maes)\n","      wmapes_24.append(wmapes)\n","      mase_24.append(mases)\n","      acc_24.append(accs)\n","      acc_90_24.append(accs_90)\n","\n","    if not round(np.mean(np.ma.masked_invalid(wmapes_24)),0)==0 and testing==True:\n","      raise AssertionError()\n","\n","    return [rmse_24, mae_24, wmapes_24, mase_24, nrmse_24, acc_24, acc_90_24]"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"_LjQ4Yb97IGx","executionInfo":{"status":"ok","timestamp":1650668350725,"user_tz":-120,"elapsed":491,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["# calculate differences to original data for many models:\n","def print_originalvalues_results(result_list, y_test_control, naive, originals=True):\n","  \n","  rmse_lst = []\n","  mae_lst = []\n","  wmape_lst = []\n","  mase_lst = []\n","  nrmse_lst = []\n","  accur_lst = []\n","  accur_90_lst = []\n","\n","  for i in range(len(result_list)):\n","    if originals == True:\n","      y_pred_fridge = preproc_target.inverse_transform(result_list[i].reshape((-1,1)))\n","      metric_list = evaluate_predictions_flat(y_test_control, y_pred_fridge, naive, testing=False)\n","    else:\n","      scaled_true = preproc_target.transform(y_test_control)\n","      scaled_naive = preproc_target.transform(naive)\n","      metric_list = evaluate_predictions_flat(scaled_true, result_list[i].reshape((-1,1)), scaled_naive, testing=False)\n","\n","    \n","    rmse_lst.append(metric_list[0])\n","    mae_lst.append(metric_list[1])\n","    wmape_lst.append(metric_list[2])\n","    mase_lst.append(metric_list[3])\n","    nrmse_lst.append(metric_list[4])\n","    accur_lst.append(metric_list[5])\n","    accur_90_lst.append(metric_list[6])\n","\n","  return rmse_lst, mae_lst, wmape_lst, mase_lst, nrmse_lst, accur_lst, accur_90_lst"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"jJk35ian7IGy","executionInfo":{"status":"ok","timestamp":1650668111162,"user_tz":-120,"elapsed":8,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["# Fil empty dataframe with the time lag observations per variable as features for 24h\n","def get_tlags_rolling_features(df, col_names, tlag):\n","\n","   dataframe = pd.DataFrame()\n","   for col in col_names:\n","     for i in range((tlag-1),0,-1):\n","       dataframe[col + '_t-'+str(i)] = df[col].shift(i).values[:]\n","     dataframe[col] = df[col]\n","   \n","   dataframe = dataframe[(tlag-1):]\n","   dataframe.dropna(inplace=True)\n","   dataframe.reset_index(drop=True, inplace=True)\n","   \n","   nparray = np.empty((dataframe.shape[0], tlag, len(col_names)))\n","   for i in range(len(col_names)):\n","      nparray[:,:,i] = dataframe.values[:,i*tlag:(i+1)*tlag]\n","   return dataframe, nparray"]},{"cell_type":"code","source":["def get_msvr_gamma(xtrain, relational=True, factor=10):\n","\n","  if relational==True:\n","    msvr_gamma = 1 / (xtrain.shape[1] * xtrain.var())\n","\n","  else:\n","    msvr_gamma = 1 / factor\n","  \n","  return msvr_gamma"],"metadata":{"id":"G9P2Mjio1KY5","executionInfo":{"status":"ok","timestamp":1650668111162,"user_tz":-120,"elapsed":8,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zaAo3yIQbvhu"},"source":["#### REFIT"]},{"cell_type":"markdown","metadata":{"id":"Yb4BwqNLUNEM"},"source":["#### Specify Experiment Parameters"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"V-g_UotyTr56","executionInfo":{"status":"ok","timestamp":1650668111163,"user_tz":-120,"elapsed":9,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["# check reshape dimension for loading original data\n","# solve seq2seq decoder output deformation (related to feature specification)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27046,"status":"ok","timestamp":1650668138201,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"},"user_tz":-120},"id":"PCXjCnqPUMTU","outputId":"d1c552f5-1b8c-4629-a667-043b1bf32c51"},"outputs":[{"output_type":"stream","name":"stdout","text":["(9330, 24, 113)\n"]}],"source":["# Load Data\n","dataset = 'refit' # 'ampds' , 'pecansd', 'greend'\n","dimension_var = 'many' # define wether it will be the baseline or a feature run-through\n","ylag = 24 # define number of time steps to predict\n","target = 'Fridge' # Specify the target Appliance\n","feature_group = 'appliances'\n","path_to_data_folder = '/content/drive/MyDrive/'\n","tune_model = 'lstm' # 'lstm', 'ffnn'\n","\n","if dataset == 'refit':\n","  data_url = f'{path_to_data_folder}data/REFIT/'\n","  reshape_dimension = 113\n","elif dataset == 'ampds':\n","  data_url = f'{path_to_data_folder}data/AMPds/'\n","  reshape_dimension = 113\n","elif dataset == 'pecansd':\n","  data_url = f'{path_to_data_folder}data/PecanSD/'\n","  reshape_dimension = 86\n","elif dataset == 'greend':\n","  data_url = f'{path_to_data_folder}data/GreenD/building0/'\n","  reshape_dimension = 86  \n","else:\n","  raise AssertionError('Please specify a valid dataset')\n","\n","df = pd.read_csv(f'{data_url}traindata_scaled.csv')\n","\n","nparray = np.loadtxt(f'{data_url}traindata_scaled.txt')\n","nparray = nparray.reshape((-1, ylag, reshape_dimension))\n","print(nparray.shape)\n","\n","# train and valid set params\n","split_ratio = 0.2\n","val_split = int(np.floor(len(df)*split_ratio))\n","target_idx = list(df.columns).index(target)-1\n","\n","# FE Selection Features:\n","if feature_group == 'baseline':\n","  col_idx = np.r_[target_idx:target_idx+1]\n","  dimension_var = 'one'\n","elif feature_group == 'appliances':\n","  if dataset in ('refit', 'ampds'):\n","    # Nur Appliances:\n","    col_idx = np.r_[0:5]\n","  elif dataset in ('pecansd', 'greend'):\n","    col_idx = np.r_[0:4]\n"," \n","elif feature_group == 'weather': \n","  if dataset in ('refit', 'ampds'):\n","    col_idx = np.r_[target_idx:target_idx+1,5:8]\n","  elif dataset in ('pecansd', 'greend'):\n","    col_idx = np.r_[target_idx:target_idx+1,4:7]\n","\n","elif feature_group == 'sinecosine': \n","  if dataset in ('refit', 'ampds'):\n","    col_idx = np.r_[target_idx:target_idx+1,90:91, 95:103]\n","  elif dataset in ('pecansd', 'greend'):\n","    col_idx = np.r_[target_idx:target_idx+1, 65:66, 70:78]\n","\n","elif feature_group == 'lon_loff': \n","  if dataset in ('refit', 'ampds'):\n","    col_idx = np.r_[target_idx:target_idx+1, 103+target_idx:105+target_idx+1]\n","  elif dataset in ('pecansd', 'greend'):\n","    col_idx = np.r_[target_idx:target_idx+1, 78+target_idx:80+target_idx+1]\n","\n","elif feature_group == 'lon_loff': \n","  if dataset in ('refit', 'ampds'):\n","    col_idx = np.r_[0:91, 95:113]\n","  elif dataset in ('pecansd', 'greend'):\n","    col_idx = np.r_[0:66, 70:86] \n","\n","elif feature_group == 'weather_sinecosine': \n","  if dataset in ('refit', 'ampds'):\n","    col_idx = np.r_[target_idx:target_idx+1, 90:91, 95:103]\n","  elif dataset in ('pecansd', 'greend'):\n","    col_idx = np.r_[target_idx:target_idx+1,65:66, 70:78] \n","elif feature_group =='autoreg_features':\n","  autoreg_features = True\n","elif feature_group =='interact_features':\n","  interact_features = True\n","elif feature_group =='vest_features':\n","  vest_features = True\n","elif feature_group =='taken_features':\n","  taken_features = True  \n","else:\n","  raise AssertionError('Please specify a valid feature group')\n","\n","\n","# Model params all models:\n","epochs = 10\n","loss = 'mse'\n","optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n","\n"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1650668138201,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"},"user_tz":-120},"id":"8ghzK32I73Xk","outputId":"918e3193-76ec-4d74-956b-7e7c0f3d709c"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE/MAE/wMAPE/MASE/NRMSE/ACCURACY\n","0.00,0.00,0.00,0.00, 0.00, 1.00\n"]}],"source":["Xtrain_arrayfe = nparray[:-val_split]\n","ytrain_arrayfe = nparray[ylag:-val_split+ylag, :, target_idx]\n","\n","Xvalid_arrayfe = nparray[-val_split:-ylag]\n","yvalid_arrayfe = nparray[-val_split+ylag:, :, target_idx]\n","\n","# get scalars and test transformation process for evaluation\n","preproc_target = load(open(f'{data_url}std_scaler_{target}.pkl', 'rb'))\n","df_tr = pd.read_csv(f'{data_url}original_traindata_imputed_outlreplaced.csv')\n","\n","# inverse transform our predictions:\n","y_valid_fridge = yvalid_arrayfe[::24, :].reshape((-1,1))\n","y_valid_fridge = preproc_target.inverse_transform(y_valid_fridge)\n","\n","#inverse transform test values\n","Xvalid_fridge = Xvalid_arrayfe[::24,:,target_idx].reshape((-1,1))\n","Xvalid_fridge = preproc_target.inverse_transform(Xvalid_fridge)\n","\n","# get part of original data that we use\n","df_valid_true = df_tr[target].iloc[-len(y_valid_fridge)-11:-11].values.reshape((-1,1)) # refit = -3/ smart -13/ ampds -13\n","\n","# calculate difference to original data\n","rmse, mae, mape_sin_nan, mase, nrmse, acc, acc_90 = evaluate_predictions_flat(df_valid_true, y_valid_fridge, test_y= Xvalid_fridge)"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":535,"status":"ok","timestamp":1650668138731,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"},"user_tz":-120},"id":"Zm-Y8zu573Xo","outputId":"9b445df6-fe81-4174-a9aa-c3116474451c"},"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE/MAE/wMAPE/MASE/NRMSE/ACCURACY\n","0.00,0.00,0.00,0.00, 0.00, 1.00\n"]}],"source":["# Load Test Data\n","Xtest_array = np.loadtxt(f'{data_url}testdata_scaled.txt')\n","Xtest_array = Xtest_array.reshape((-1,24,reshape_dimension)) \n","Xtest = Xtest_array[:-1, :, :].copy()\n","ytest = Xtest_array[1:, :, target_idx].copy()\n","\n","# Check for Testdata:\n","df_t = pd.read_csv(f'{data_url}original_testdata_imputed_outlreplaced.csv')\n","\n","y_test_fridge = ytest.reshape((-1,1))\n","y_test_fridge = preproc_target.inverse_transform(y_test_fridge)\n","y_test_fridge_wind = y_test_fridge.reshape(ytest.shape)\n","\n","#inverse transform test values\n","Xtest_fridge = Xtest[:,:,target_idx].reshape((-1,1))\n","Xtest_fridge = preproc_target.inverse_transform(Xtest_fridge)\n","Xtest_fridge_wind = Xtest_fridge.reshape(Xtest[:,:,0].shape)\n","\n","# get part of original data that we use\n","df_test_true = df_t[target].iloc[-len(y_test_fridge)-24:-24].values.reshape((-1,1)) # refit -24  / Ampds -24\n","df_test_true_wind = df_test_true.reshape(Xtest[:,:,0].shape)\n","\n","# calculate difference to original data\n","rmse, mae, mape_sin_nan, mase, nrmse, acc, acc_90 = evaluate_predictions_flat(df_test_true, y_test_fridge, test_y = Xtest_fridge)"]},{"cell_type":"markdown","metadata":{"id":"gybi688wcdn9"},"source":["#### Daten für Experimente"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650668138731,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"},"user_tz":-120},"id":"PxXmE_8xER3W","outputId":"9fdd5f2d-fb5f-4a6c-b0ea-0f1bb59ea644"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of train and val array: (7446, 24, 5), (1860, 24, 5)\n","Shape of train and val y array: (7446, 24), (1860, 24)\n","Shape of test data X-array and y-array: (112, 24, 5), (112, 24)\n","(7446, 120)\n","(112, 120)\n"]}],"source":["Xtrain_arrayfe = Xtrain_arrayfe[:,:,col_idx]\n","Xvalid_arrayfe = Xvalid_arrayfe[:,:,col_idx]\n","Xtest = Xtest[:,:,col_idx]\n","\n","# Input XGBoost, MSVR and FFNN:\n","X_train = Xtrain_arrayfe.reshape((Xtrain_arrayfe.shape[0],-1))\n","X_valid = Xvalid_arrayfe.reshape((Xvalid_arrayfe.shape[0],-1))\n","X_test = Xtest.reshape((Xtest.shape[0],-1))\n","\n","print(f'Shape of train and val array: {Xtrain_arrayfe.shape}, {Xvalid_arrayfe.shape}')\n","print(f'Shape of train and val y array: {ytrain_arrayfe.shape}, {yvalid_arrayfe.shape}')\n","print(f'Shape of test data X-array and y-array: {Xtest.shape}, {ytest.shape}') \n","print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"5ohFEoLCzHoe"},"source":["#### SVR"]},{"cell_type":"markdown","metadata":{"id":"ZcUOBBlWc9yX"},"source":["##### Code"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"704HgzHdY3Ta","executionInfo":{"status":"ok","timestamp":1650668139167,"user_tz":-120,"elapsed":438,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics.pairwise import pairwise_kernels\n","\n","class MSVR():\n","    def __init__(self, kernel='rbf', degree=3, gamma=None, coef0=0.0, tol=0.001, C=1.0, epsilon=0.1):\n","        super(MSVR, self).__init__()\n","        self.kernel = kernel\n","        self.degree = degree\n","        self.gamma = gamma\n","        self.coef0 = coef0\n","        self.tol = tol\n","        self.C = C\n","        self.epsilon = epsilon\n","        self.Beta = None\n","        self.NSV = None\n","        self.xTrain = None\n","\n","    def fit(self, x, y):\n","        self.xTrain = x.copy()\n","        C = self.C\n","        epsi = self.epsilon\n","        tol = self.tol\n","\n","        n_m = np.shape(x)[0]  # num of samples\n","        n_d = np.shape(x)[1]  # input data dimensionality\n","        n_k = np.shape(y)[1]  # output data dimensionality (output variables)\n","\n","        # H = kernelmatrix(ker, x, x, par)\n","        H = pairwise_kernels(x, x, metric=self.kernel, filter_params=True,\n","                             degree=self.degree, gamma=self.gamma, coef0=self.coef0)\n","\n","        self.Beta = np.zeros((n_m, n_k))\n","\n","        #E = prediction error per output (n_m * n_k)\n","        E = y - np.dot(H, self.Beta)\n","        #RSE\n","        u = np.sqrt(np.sum(E**2, 1, keepdims=True))\n","\n","        #RMSE\n","        RMSE = []\n","        RMSE_0 = np.sqrt(np.mean(u**2))\n","        RMSE.append(RMSE_0)\n","\n","        #points for which prediction error is larger than epsilon\n","        i1 = np.where(u > epsi)[0]\n","\n","        #set initial values of alphas a (n_m * 1)\n","        a = 2 * C * (u - epsi) / u\n","\n","        #L (n_m * 1)\n","        L = np.zeros(u.shape)\n","\n","        # we modify only entries for which  u > epsi. with the sq slack\n","        L[i1] = u[i1]**2 - 2 * epsi * u[i1] + epsi**2\n","\n","        #Lp is the quantity to minimize (sq norm of parameters + slacks)\n","        Lp = []\n","        BetaH = np.dot(np.dot(self.Beta.T, H), self.Beta)\n","        Lp_0 = np.sum(np.diag(BetaH), 0) / 2 + C * np.sum(L)/2\n","        Lp.append(Lp_0)\n","\n","        eta = 1\n","        k = 1\n","        hacer = 1\n","        val = 1\n","\n","        while(hacer):\n","            Beta_a = self.Beta.copy()\n","            E_a = E.copy()\n","            u_a = u.copy()\n","            i1_a = i1.copy()\n","\n","            M1 = H[i1][:, i1] + \\\n","                np.diagflat(1/a[i1]) + 1e-10 * np.eye(len(a[i1]))\n","\n","            #compute betas\n","            #       sal1 = np.dot(np.linalg.pinv(M1),y[i1])  #求逆or广义逆（M-P逆）无法保证M1一定是可逆的？\n","            sal1 = np.dot(np.linalg.inv(M1), y[i1])\n","\n","            eta = 1\n","            self.Beta = np.zeros(self.Beta.shape)\n","            self.Beta[i1] = sal1.copy()\n","\n","            #error\n","            E = y - np.dot(H, self.Beta)\n","            #RSE\n","            u = np.sqrt(np.sum(E**2, 1)).reshape(n_m, 1)\n","            i1 = np.where(u >= epsi)[0]\n","\n","            L = np.zeros(u.shape)\n","            L[i1] = u[i1]**2 - 2 * epsi * u[i1] + epsi**2\n","\n","            #%recompute the loss function\n","            BetaH = np.dot(np.dot(self.Beta.T, H), self.Beta)\n","            Lp_k = np.sum(np.diag(BetaH), 0) / 2 + C * np.sum(L)/2\n","            Lp.append(Lp_k)\n","\n","            #Loop where we keep alphas and modify betas\n","            while(Lp[k] > Lp[k-1]):\n","                eta = eta/10\n","                i1 = i1_a.copy()\n","\n","                self.Beta = np.zeros(self.Beta.shape)\n","                #%the new betas are a combination of the current (sal1)\n","                #and of the previous iteration (Beta_a)\n","                self.Beta[i1] = eta*sal1 + (1-eta)*Beta_a[i1]\n","\n","                E = y - np.dot(H, self.Beta)\n","                u = np.sqrt(np.sum(E**2, 1)).reshape(n_m, 1)\n","\n","                i1 = np.where(u >= epsi)[0]\n","\n","                L = np.zeros(u.shape)\n","                L[i1] = u[i1]**2 - 2 * epsi * u[i1] + epsi**2\n","                BetaH = np.dot(np.dot(self.Beta.T, H), self.Beta)\n","                Lp_k = np.sum(np.diag(BetaH), 0) / 2 + C * np.sum(L)/2\n","                Lp[k] = Lp_k\n","\n","                #stopping criterion 1\n","                if(eta < 1e-16):\n","                    Lp[k] = Lp[k-1] - 1e-15\n","                    self.Beta = Beta_a.copy()\n","\n","                    u = u_a.copy()\n","                    i1 = i1_a.copy()\n","\n","                    hacer = 0\n","\n","            #here we modify the alphas and keep betas\n","            a_a = a.copy()\n","            a = 2 * C * (u - epsi) / u\n","\n","            RMSE_k = np.sqrt(np.mean(u**2))\n","            RMSE.append(RMSE_k)\n","\n","            if((Lp[k-1]-Lp[k])/Lp[k-1] < tol):\n","                hacer = 0\n","\n","            k = k + 1\n","\n","            #stopping criterion #algorithm does not converge. (val = -1)\n","            if(len(i1) == 0):\n","                hacer = 0\n","                self.Beta = np.zeros(self.Beta.shape)\n","                val = -1\n","\n","        self.NSV = len(i1)\n","\n","    def predict(self, x):\n","        H = pairwise_kernels(x, self.xTrain, metric=self.kernel, filter_params=True,\n","                             degree=self.degree, gamma=self.gamma, coef0=self.coef0)\n","        yPred = np.dot(H, self.Beta)\n","        return yPred\n","\n","    # def score(self,x):"]},{"cell_type":"markdown","metadata":{"id":"P0GtueHodCS-"},"source":["##### Predictions"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"7Xc44iYMbL5i","colab":{"base_uri":"https://localhost:8080/","height":519},"outputId":"528b6ce5-a75d-4d13-f6f0-7a59accfbb13","executionInfo":{"status":"error","timestamp":1650668333620,"user_tz":-120,"elapsed":194456,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(2688, 1)\n","RMSE/MAE/wMAPE/MASE/NRMSE/ACCURACY\n","19.92,16.10,1.01,0.95, 0.20, 0.80\n","(2688, 1)\n","RMSE/MAE/wMAPE/MASE/NRMSE/ACCURACY\n","17.92,14.78,0.93,0.87, 0.18, 0.80\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-30c8f2d1996e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mmsvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mga\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mmsvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_arrayfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0my_pred_fridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-58-51e98f5dfc8c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m#compute betas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m#       sal1 = np.dot(np.linalg.pinv(M1),y[i1])  #求逆or广义逆（M-P逆）无法保证M1一定是可逆的？\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0msal1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# params:\n","gamma_range= [1/100, 1/1000, 1 /(X_train.shape[1] * X_train.var())]\n","epsilon_range= [1,0.1, 0.01, 0.001, 0.0001]\n","c_range = [100, 10, 1, 0.1, 0.01, 0.001]\n","msvr_best = 1000\n","\n","for ga in gamma_range:\n","  for ep in epsilon_range:\n","    for cr in c_range:\n","      msvr = MSVR(kernel = 'rbf', gamma = ga, epsilon=ep, degree=2, C=cr) \n","      msvr.fit(X_train, ytrain_arrayfe)\n","      yhat = msvr.predict(X_test)\n","      y_pred_fridge = preproc_target.inverse_transform(yhat)\n","      y_pred_fridge = y_pred_fridge.reshape(-1,1)\n","      print(y_pred_fridge.shape)\n","      msvr_tuning_results = evaluate_predictions_flat(df_test_true, y_pred_fridge, test_y = Xtest_fridge, testing=False)\n","      if msvr_tuning_results[0]>=msvr_best:\n","        best_params = {'Gamma': ga, 'epsilon': ep, 'c_value': cr}\n","        msvr_best=msvr_tuning_results[0]\n","\n","print(best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RH4cW3OMGt9v","executionInfo":{"status":"aborted","timestamp":1650668333613,"user_tz":-120,"elapsed":31,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["import sklearn\n","# Compare predictins against multi step SVR:\n","class VectorRegression(sklearn.base.BaseEstimator):\n","    def __init__(self, estimator):\n","        self.estimator = estimator\n","\n","    def fit(self, X, y):\n","        n, m = y.shape\n","        # Fit a separate regressor for each column of y\n","        self.estimators_ = [sklearn.base.clone(self.estimator).fit(X, y[:, i])\n","                               for i in range(m)]\n","        return self\n","\n","    def predict(self, X):\n","        # Join regressors' predictions\n","        res = [est.predict(X)[:, np.newaxis] for est in self.estimators_]\n","        return np.hstack(res)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVIBu98PGyOA","executionInfo":{"status":"aborted","timestamp":1650668333615,"user_tz":-120,"elapsed":32,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["from sklearn.svm import SVR\n","\n","simple_svr = VectorRegression(SVR(epsilon=0.1, C=0.1))\n","simple_svr.fit(X_train, ytrain_arrayfe)\n","yhat = simple_svr.predict(X_test)\n","\n","y_pred_fridge = yhat.reshape((-1,1))\n","y_pred_fridge = preproc_target.inverse_transform(y_pred_fridge)\n","svr_tuning_results = evaluate_predictions_flat(df_test_true, y_pred_fridge, test_y = Xtest_fridge, testing=False)\n","print(svr_tuning_results[0])"]},{"cell_type":"markdown","metadata":{"id":"Ss454fqYzEro"},"source":["#### Neural Networks Tuning"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"-aRENDhfACf3","executionInfo":{"status":"ok","timestamp":1650668358985,"user_tz":-120,"elapsed":370,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["if tune_model == 'ffnn':\n","  def get_keras_model(neurons_per_layer_return, \n","                      dropout_rate, \n","                      lky_lr, nr_layers):\n","  \n","      # define the layers.\n","      # Define input layers\n","      input = Input(X_train[0].shape)\n","      for i in range(nr_layers):\n","        layer = Dense(neurons_per_layer_return)(input)\n","        lr1 = LeakyReLU(alpha=lky_lr)(layer)\n","        drpt1 = Dropout(dropout_rate)(lr1)\n","  \n","      outputs = Dense(24)(drpt1)  \n","  \n","      model = tf.keras.Model(inputs=input, outputs=outputs)\n","      return model\n","\n","else:\n","  def get_keras_model(neurons_per_layer_return, \n","                      dropout_rate, \n","                      lky_lr, nr_layers):\n","  \n","      # define the layers.\n","      inputs = Input(Xtrain_arrayfe[0].shape)  # input layer.\n","      x = Dropout(dropout_rate)(inputs) # dropout on the weights.\n","      \n","      # Add the hidden layers.\n","      x = LSTM(neurons_per_layer_return, return_sequences=True,  input_shape=Xtrain_arrayfe.shape)(x)\n","      #x = LeakyReLU(alpha=lky_lr)(x)\n","      x = Dropout(dropout_rate)(x)\n","  \n","      x = LSTM(neurons_per_layer_return)(x)\n","      #x = LeakyReLU(alpha=lky_lr)(x)\n","      x = Dropout(dropout_rate)(x)        \n","      # output layer.\n","      outputs = Dense(24, activation='linear')(x)\n","      outputs = LeakyReLU(alpha=lky_lr)(outputs)\n","  \n","      model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","      return model"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"MkILLGN9TG6l","executionInfo":{"status":"ok","timestamp":1650668359405,"user_tz":-120,"elapsed":6,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["\n","  \n","\n","# This function takes in the hyperparameters and returns a score (Cross validation).\n","def keras_mlp_cv_score(parameterization, weight=None):\n","    \n","    model = get_keras_model(parameterization.get('neurons_per_layer_return'),\n","                            parameterization.get('dropout_rate'),\n","                            parameterization.get('lky_lr'),\n","                            parameterization.get('nr_layers'))\n","    \n","    opt = parameterization.get('optimizer')\n","    opt = opt.lower()\n","    \n","    learning_rate = parameterization.get('learning_rate')\n","    \n","    if opt == 'adam':\n","        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    \n","    NUM_EPOCHS = 20\n","    \n","    # Specify the training configuration.\n","    model.compile(optimizer=optimizer,\n","                  loss=tf.keras.losses.MeanSquaredError(),\n","                  metrics=['mse'])\n","\n","    data = Xtrain_arrayfe\n","    labels = ytrain_arrayfe\n","    \n","    # fit the model using a 20% validation set.\n","    res = model.fit(data, labels, epochs=NUM_EPOCHS, batch_size=parameterization.get('batch_size'),\n","                    validation_split=0.2)\n","    \n","    # look at the last 10 epochs. Get the mean and standard deviation of the validation score.\n","    last10_scores = np.array(res.history['val_loss'][-10:])\n","    mean = last10_scores.mean()\n","    sem = last10_scores.std()\n","    \n","    # If the model didn't converge then set a high loss.\n","    if np.isnan(mean):\n","        return 9999.0, 0.0\n","    \n","    return mean, sem"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"IB5FRpzRWzPK","executionInfo":{"status":"ok","timestamp":1650668359406,"user_tz":-120,"elapsed":7,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["# Define the search space.\n","parameters=[\n","    {\n","        \"name\": \"learning_rate\",\n","        \"type\": \"range\",\n","        \"bounds\": [0.0001, 0.5],\n","        \"log_scale\": True,\n","    },\n","    {\n","        \"name\": \"dropout_rate\",\n","        \"type\": \"range\",\n","        \"bounds\": [0.01, 0.5],\n","        \"log_scale\": True,\n","    },\n","        {\n","        \"name\": \"neurons_per_layer_return\",\n","        \"type\": \"range\",\n","        \"bounds\": [1, 400],\n","        \"value_type\": \"int\"\n","    },\n","    {\n","        \"name\": \"batch_size\",\n","        \"type\": \"choice\",\n","        \"values\": [8, 16, 32, 64, 128],\n","    },\n","    \n","    {\n","        \"name\": \"lky_lr\",\n","        \"type\": \"choice\",\n","        \"values\": [0.1, 0.2, 0.5],\n","    },\n","    {\n","        \"name\": \"optimizer\",\n","        \"type\": \"choice\",\n","        \"values\": ['adam'],\n","    },\n","    {\n","        \"name\": \"nr_layers\",\n","        \"type\": \"range\",\n","        \"bounds\": [1, 6],\n","        \"value_type\": \"int\"\n","    },\n","]"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"2SABRxk7yxe2","colab":{"base_uri":"https://localhost:8080/","height":211,"output_embedded_package_id":"1TXFz8z66g_rB9dcX3p_e1T4QAvd2vCS6"},"executionInfo":{"status":"ok","timestamp":1650668367281,"user_tz":-120,"elapsed":7882,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}},"outputId":"72b661e3-dd15-4dfb-ba91-6f10a0278bc0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["init_notebook_plotting()\n","\n","ax_client = AxClient()\n","\n","# create the experiment.\n","ax_client.create_experiment(\n","    name=\"keras_experiment\",\n","    parameters=parameters,\n","    objective_name='keras_cv',\n","    minimize=True)\n","\n","def evaluate(parameters):\n","    return {\"keras_cv\": keras_mlp_cv_score(parameters)}"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"83xNqrH7zLo8","colab":{"base_uri":"https://localhost:8080/","height":731},"executionInfo":{"status":"error","timestamp":1650668386213,"user_tz":-120,"elapsed":18955,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}},"outputId":"7f0f1907-6b33-47e4-ece2-9e9934d6b613"},"outputs":[{"output_type":"stream","name":"stderr","text":["[INFO 04-22 22:59:19] ax.service.ax_client: Generated new trial 0 with parameters {'learning_rate': 0.000368, 'dropout_rate': 0.018984, 'neurons_per_layer_return': 15, 'batch_size': 32, 'lky_lr': 0.2, 'nr_layers': 5, 'optimizer': 'adam'}.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","187/187 [==============================] - 9s 11ms/step - loss: 1.0123 - mse: 1.0123 - val_loss: 0.9510 - val_mse: 0.9510\n","Epoch 2/20\n","187/187 [==============================] - 2s 8ms/step - loss: 1.0028 - mse: 1.0028 - val_loss: 0.9498 - val_mse: 0.9498\n","Epoch 3/20\n","187/187 [==============================] - 2s 12ms/step - loss: 0.9950 - mse: 0.9950 - val_loss: 0.9476 - val_mse: 0.9476\n","Epoch 4/20\n","187/187 [==============================] - 2s 12ms/step - loss: 0.9902 - mse: 0.9902 - val_loss: 0.9460 - val_mse: 0.9460\n","Epoch 5/20\n","187/187 [==============================] - 2s 10ms/step - loss: 0.9876 - mse: 0.9876 - val_loss: 0.9444 - val_mse: 0.9444\n","Epoch 6/20\n","187/187 [==============================] - 1s 7ms/step - loss: 0.9861 - mse: 0.9861 - val_loss: 0.9432 - val_mse: 0.9432\n","Epoch 7/20\n","187/187 [==============================] - 2s 9ms/step - loss: 0.9846 - mse: 0.9846 - val_loss: 0.9439 - val_mse: 0.9439\n","Epoch 8/20\n","187/187 [==============================] - 2s 10ms/step - loss: 0.9837 - mse: 0.9837 - val_loss: 0.9436 - val_mse: 0.9436\n","Epoch 9/20\n","187/187 [==============================] - 2s 11ms/step - loss: 0.9832 - mse: 0.9832 - val_loss: 0.9428 - val_mse: 0.9428\n","Epoch 10/20\n"," 99/187 [==============>...............] - ETA: 0s - loss: 1.0020 - mse: 1.0020"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-ccf8fee2c2d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0max_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-64-e0a784fe308e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"keras_cv\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras_mlp_cv_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-62-767b443aa06a>\u001b[0m in \u001b[0;36mkeras_mlp_cv_score\u001b[0;34m(parameterization, weight)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# fit the model using a 20% validation set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     res = model.fit(data, labels, epochs=NUM_EPOCHS, batch_size=parameterization.get('batch_size'),\n\u001b[0;32m---> 32\u001b[0;31m                     validation_split=0.2)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# look at the last 10 epochs. Get the mean and standard deviation of the validation score.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for i in range(25):\n","    parameters, trial_index = ax_client.get_next_trial()\n","    ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameters))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkUL9PTwKP05","executionInfo":{"status":"aborted","timestamp":1650668386210,"user_tz":-120,"elapsed":8,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["best_parameters, values = ax_client.get_best_parameters()\n","\n","# the best set of parameters.\n","for k in best_parameters.items():\n","  print(k)\n","\n","\n","# the best score achieved.\n","means, covariances = values\n","print(means)\n","\n","# mit leaky relu\n","#('learning_rate', 0.00013804406758572161)\n","#('dropout_rate', 0.05679751211790285)\n","#('neurons_per_layer_return', 172)\n","#('batch_size', 32)\n","#('lky_lr', 0.2)\n","#('optimizer', 'adam')\n","#{'keras_cv': 0.8750310514613202}\n","\n","#ohne leaky relu\n","#('learning_rate', 0.0001)\n","#('dropout_rate', 0.0755114162939656)\n","#('neurons_per_layer_return', 377)\n","#('batch_size', 64)\n","#('lky_lr', 0.1)\n","#('optimizer', 'adam')\n","#\n","#{'keras_cv': 0.872819151614518}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0kKAv3v02ZBV","executionInfo":{"status":"aborted","timestamp":1650668386211,"user_tz":-120,"elapsed":9,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["loss = 'mse'\n","optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n","drpt1_rate = 0.06\n","hidd_dim_lstm1 = 172\n","hidd_dim_lstm2 = 172\n","lr1_alpha = 0.2\n","\n","start = time.time()\n","# Train Model 10 Fold:\n","lstm_result_lst = []\n","for i in [42, 10, 567, 239, 400, 1390, 380, 9, 27, 769]:\n","  # Define input layers\n","  sequential_input = Input(Xtrain_arrayfe[0].shape)\n","  \n","  # Model Architecture: LSTM\n","  lstm1 = LSTM(hidd_dim_lstm1, return_sequences=True, input_shape=Xtrain_arrayfe.shape)(sequential_input)\n","  lr1 = LeakyReLU(alpha=lr1_alpha)(lstm1)\n","  drpt1 = Dropout(drpt1_rate)(lr1)\n","  lstm2 = LSTM(hidd_dim_lstm2)(drpt1) #, return_sequences=True\n","  lr2 = LeakyReLU(alpha=lr1_alpha)(lstm2)\n","  drpt2 = Dropout(drpt1_rate)(lr2)\n","\n","  dense = Dense(24)(drpt2)\n","  outputs = LeakyReLU(alpha=lr1_alpha)(dense)\n","\n","  # Define the model\n","  lstm = Model(inputs=sequential_input, outputs=outputs)\n","  lstm.compile(loss=loss, optimizer=optimizer)\n","  \n","  # Training loop\n","  seed_value = i\n","  os.environ['PYTHONHASHSEED']=str(seed_value)\n","  random.seed(seed_value)\n","  np.random.seed(seed_value)\n","  tf.compat.v1.set_random_seed(seed_value)\n","  lstm.fit(Xtrain_arrayfe, ytrain_arrayfe, validation_data = (Xvalid_arrayfe, yvalid_arrayfe), epochs = 50, batch_size=32) #\n","  y_pred = lstm.predict(Xtest)\n","  lstm_result_lst.append(y_pred)\n","  lstm.reset_states() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnd-fq4H42b1","executionInfo":{"status":"aborted","timestamp":1650668386212,"user_tz":-120,"elapsed":10,"user":{"displayName":"Antonia Deeplearning","userId":"03469055858719879397"}}},"outputs":[],"source":["rmse_lst, mae_lst, mape_lst, mase_lst, log_acc_lst, nrmse_lst = print_originalvalues_results(lstm_result_lst, df_test_true, Xtest_fridge)\n","\n","print(rmse_lst)\n","print(mae_lst)\n","print(mape_lst)\n","print(mase_lst)\n","print(log_acc_lst)\n","print(nrmse_lst)\n","\n","print('Mean RMSE, MAE, MAPE, MASE, LOG_ACC, NRMSE:')\n","print(f'{sum(rmse_lst)/len(rmse_lst):.2f}/{sum(mae_lst)/len(mae_lst):.2f}/{sum(mape_lst)/len(mape_lst):.2f}/{sum(mase_lst)/len(mase_lst):.2f}/{sum(log_acc_lst)/len(log_acc_lst):.2f}/{sum(nrmse_lst)/len(nrmse_lst):.2f}')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Rq5OsytEbpaK","zaAo3yIQbvhu","gybi688wcdn9","JMMWjh1bcyTR","1_P3GJwccQoK","F-tHY4gsdSZG","xkpkmznrWy0D","5ohFEoLCzHoe","Ss454fqYzEro","4Yhu8nqrGA54","K4pNpfcNGQb_","Ru67l__bCVSK","cLlCaUaSXxb_","sKcznG_eZVvv","DIxjYlDfZYJp","1ZGuY_WEerh4","07t_ZnlpAC46","rMiniM2DgUii","VS6knU-5o20o","cbjSjcVoV9tk","TyVx4Q3NVgmI","pQDXEboggmc0"],"name":"model_tuning.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}